<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Riccardo Cadei | publications</title>
  <meta name="description" content="Riccardo Cadei's Portfolio">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />
  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/css/all.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Riccardo</span> Cadei</a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">

          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
            </a>
          </li>   
          
          <li class="nav-item navbar-active font-weight-bold">
            <a class="nav-link" href="/publications/">
              Publications
              <span class="sr-only">(current)</span>
            </a>
          </li>
      
          <li class="nav-item ">
            <a class="nav-link" href="/projects/">
              Projects
            </a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="/cv/">
              CV
            </a>
          </li>
            
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
  <h1>Publications</h1>
  
  <p>
    <!-- Current research projects:
    <ul>

      <li>
        Interpretable Inference of Heterogeneous Treatment Effects in <a href="https://www.hsph.harvard.edu/nsaph/" target="_blank">National Studies on Air Pollution and Health</a> group at Harvard;
      </li>

    </ul>
    
    Stopped/Not published research projects:
    <ul>

      <li>
        Deep Learning for Causal Modeling and interpretation of acoustic subsurface data for anomaly detection and hazard prevention at <a href="http://media.corporate-ir.net/media_files/irol/97/97513/2017ar/interactive/research-center.html" target="_blank">Schlumberger-Doll Research</a>;
      </li>

      <li>
        Upper-body Posture Detection using Deep Learning at <a href="https://www.epfl.ch/labs/mlo/igh-intelligent-global-health/" target="_blank">Intelligent Global Health Lab</a> at EPFL.
      </li>

    </ul> -->
   
    List of my publications in reversed chronological order.
  </p>


  <!--2025-->
  <div class="row m-0 p-0" style="border-bottom: 1px solid #ddd;">
    <div class="col-sm-11 p-0">

      <!--Cadei 2025 NeurIPS-workshop-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://iclr.cc/" target="_blank">
          NeurIPS
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="tortu2024nct" class="col p-0">
            <h5 class="title mb-0">The Narcissus Hypothesis: Descending to the Rung of Illusion
            </h5>
            <div class="author">
              <em> 
                <b>Riccardo Cadei</b>*;
                Christian Internò*
              </em>  
            </div>

            <div><p class="periodical font-italic">
              arXiv <br>
              Workshop on Evaluating the Evolving LLM Lifecycle at NeurIPS, 2025
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#cadei2025narcissus-abstract" role="button" aria-expanded="false" aria-controls="cadei2025narcissus-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2509.17999" target="_blank">Paper</a>
              <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/CausalLearningAI/causal-lifting" target="_blank">Code</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://figshare.com/s/9a490b6f6eeebd73350b" target="_blank">Data</a> -->
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://openreview.net/forum?id=I9CJp7hcZI&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2025%2FWorkshop%2FLLM_Evaluation%2FAuthors%23your-submissions)" target="_blank">Short Version (NeurIPS'25)</a>
              <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://nsaph-software.github.io/CRE/" target="_blank">Website</a> -->
            </div>
    
            <div class="col mt-2 p-0">
              <div id="cadei2025narcissus-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                   Modern foundational models increasingly reflect not just world knowledge, but patterns of human preference embedded in their training data. We hypothesize that recursive alignment-via human feedback and model-generated corpora-induces a social desirability bias, nudging models to favor agreeable or flattering responses over objective reasoning. We refer to it as the Narcissus Hypothesis and test it across 31 models using standardized personality assessments and a novel Social Desirability Bias score. Results reveal a significant drift toward socially conforming traits, with profound implications for corpus integrity and the reliability of downstream inferences. We then offer a novel epistemological interpretation, tracing how recursive bias may collapse higher-order reasoning down Pearl's Ladder of Causality, culminating in what we refer to as the Rung of Illusion.
                </div>
            </div>
            
          </div>
        </div>
      </div></li>

      <!--Yao 2025 arXiv-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://arxiv.org/" target="_blank">
          NeurIPS
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="yao2025third" class="col p-0">
            <h5 class="title mb-0">The Third Pillar of Causal Analysis? A Measurement Perspective on Causal Representations
            </h5>
            <div class="author">
              <em> 
                Dingling Yao;
                Shimeng Huang;
                <b>Riccardo Cadei</b>;
                Kun Zhang;
                Francesco Locatello
              </em>  
            </div>

            <div><p class="periodical font-italic">
              Advances in Neural Information Processing Systems (NeurIPS), 2025 <br>
              Workshop on Scaling Up Intervention Models at ICML, 2025
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#yao2025third-abstract" role="button" aria-expanded="false" aria-controls="yao2024unifying-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2505.17708" target="_blank">Paper</a>
              <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/CausalLearningAI/ISTAnt" target="_blank">Code</a> -->
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://openreview.net/forum?id=VBiEZdYagz" target="_blank">Short Version (ICML'25)</a>
              <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://nsaph-software.github.io/CRE/" target="_blank">Website</a> -->
            </div>
    
            <div class="col mt-2 p-0">
              <div id="yao2025third-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  Causal reasoning and discovery, two fundamental tasks of causal analysis, often face challenges in applications due to the complexity, noisiness, and high-dimensionality of real-world data. Despite recent progress in identifying latent causal structures using causal representation learning (CRL), what makes learned representations useful for causal downstream tasks and how to evaluate them are still not well understood. In this paper, we reinterpret CRL using a measurement model framework, where the learned representations are viewed as proxy measurements of the latent causal variables. Our approach clarifies the conditions under which learned representations support downstream causal reasoning and provides a principled basis for quantitatively assessing the quality of representations using a new Test-based Measurement EXclusivity (T-MEX) score. We validate T-MEX across diverse causal inference scenarios, including numerical simulations and real-world ecological video analysis, demonstrating that the proposed framework and corresponding score effectively assess the identification of learned representations and their usefulness for causal downstream tasks.</div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>

      <!--Cadei 2025 ICML-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://iclr.cc/" target="_blank">
          NeurIPS
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="tortu2024nct" class="col p-0">
            <h5 class="title mb-0">Causal Lifting of Neural Representations: Zero-Shot Generalization for Causal Inferences
            </h5>
            <div class="author">
              <em> 
                <b>Riccardo Cadei</b>;
                Ilker Demirel;
                Piersilvio De Bartolomeis;
                Lukas Lindorfer; 
                Sylvia Cremer; 
                Cordelia Schmid; 
                Francesco Locatello
              </em>  
            </div>

            <div><p class="periodical font-italic">
              Advances in Neural Information Processing Systems (NeurIPS), 2025 <br>
              Workshop on (i) Spurious Correlation and Shortcut Learning and (ii) XAI4Science at ICLR, 2025
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#cadei2025causallifting-abstract" role="button" aria-expanded="false" aria-controls="cadei2025causallifting-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2502.06343" target="_blank">Paper</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/CausalLearningAI/causal-lifting" target="_blank">Code</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://figshare.com/s/9a490b6f6eeebd73350b" target="_blank">Data</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://openreview.net/forum?id=HQSaQPOcyP&referrer=%5Bthe%20profile%20of%20Sylvia%20Cremer%5D(%2Fprofile%3Fid%3D~Sylvia_Cremer1)" target="_blank">Short Version (ICLR'25)</a>
              <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://nsaph-software.github.io/CRE/" target="_blank">Website</a> -->
            </div>
    
            <div class="col mt-2 p-0">
              <div id="cadei2025causallifting-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                   In many scientific domains, the cost of data annotation limits the scale and pace of experimentation. Yet, modern machine learning systems offer a promising alternative, provided their predictions yield correct conclusions. We focus on Prediction-Powered Causal Inferences (PPCI), i.e., estimating the treatment effect in a target experiment with unlabeled factual outcomes, retrievable zero-shot from a pre-trained model. We first identify the conditional calibration property to guarantee valid PPCI at population level. Then, we introduce causal lifting, a new causal lifting constraint transferring validity across experiments, which we propose to enforce in practice in Deconfounded Empirical Risk Minimization, our new model-agnostic training objective. We validate our method on synthetic and real-world scientific data, offering solutions to instances not solvable by vanilla Empirical Risk Minimization and invariant training. In particular, we solve zero-shot PPCI on the ISTAnt dataset for the first time, fine-tuning a foundational model on our replica dataset of their ecological experiment with a different recording platform and treatment.    
                </div>
            </div>
            
          </div>
        </div>
      </div></li>

      <!--Yao 2025 ICLR-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://iclr.cc/" target="_blank">
          ICLR
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="tortu2024nct" class="col p-0">
            <h5 class="title mb-0">Unifying Causal Representation Learning with the Invariance Principle
            </h5>
            <div class="author">
              <em> 
                Dingling Yao;
                Dario Rancati;
                <b>Riccardo Cadei</b>;
                Marco Fumero;
                Francesco Locatello
              </em>  
            </div>

            <div><p class="periodical font-italic">
              International Conference on Learning Representations (ICLR), 2025 <br>
              Workshop on (i) Causal Representation Learning and (ii) UniReps at NeurIPS, 2024
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#yao2024unifying-abstract" role="button" aria-expanded="false" aria-controls="yao2024unifying-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2409.02772" target="_blank">Paper</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/CausalLearningAI/ISTAnt" target="_blank">Code</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://openreview.net/forum?id=LaU3p8Pj0D&noteId=BsDCGz6M5E" target="_blank">Short Version (NeurIPS'24)</a>
              <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://nsaph-software.github.io/CRE/" target="_blank">Website</a> -->
            </div>
    
            <div class="col mt-2 p-0">
              <div id="yao2024unifying-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  Causal representation learning aims at recovering latent causal variables from high-dimensional observations to solve causal downstream tasks, such as predicting the effect of new interventions or more robust classification. A plethora of methods have been developed, each tackling carefully crafted problem settings that lead to different types of identifiability. The folklore is that these different settings are important, as they are often linked to different rungs of Pearl's causal hierarchy, although not all neatly fit. Our main contribution is to show that many existing causal representation learning approaches methodologically align the representation to known data symmetries. Identification of the variables is guided by equivalence classes across different data pockets that are not necessarily causal. This result suggests important implications, allowing us to unify many existing approaches in a single method that can mix and match different assumptions, including non-causal ones, based on the invariances relevant to our application. It also significantly benefits applicability, which we demonstrate by improving treatment effect estimation on real-world high-dimensional ecological data. Overall, this paper clarifies the role of causality assumptions in the discovery of causal variables and shifts the focus to preserving data symmetries.</div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>

    </div>

    <div class="col-sm-1 align-self-end mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2025</h3>
    </div>
  </div>

  <!--2024-->
  <div class="row m-0 p-0" style="border-bottom: 1px solid #ddd;">
    <div class="col-sm-11 p-0">

      <!--Cadei 2024 NeurIPS-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://neurips.cc/" target="_blank">
          NeurIPS
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="tortu2024nct" class="col p-0">
            <h5 class="title mb-0">Smoke and Mirrors in Causal Downstream Tasks
            </h5>
            <div class="author">
              <em> 
                <b>Riccardo Cadei</b>;
                Lukas Lindorfer;
                Sylvia Cremer;
                Cordelia Schmid;
                Francesco Locatello
              </em>  
            </div>

            <div><p class="periodical font-italic">
              Advances in Neural Information Processing Systems (NeurIPS), 2024 <br>
              Workshop in AI for Science: Scaling in AI for Scientific Discovery at ICML, 2024
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#cadei2024smoke-nips-abstract" role="button" aria-expanded="false" aria-controls="cadei2024smoke-nips-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2405.17151" target="_blank">Paper</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/CausalLearningAI/ISTAnt" target="_blank">Code</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://figshare.com/s/0970e149cfe72089c771?file=48137317" target="_blank">Data</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://openreview.net/forum?id=gjd9E4IUur" target="_blank">Short Version (ICML'24)</a>
            </div>
    
            <div class="col mt-2 p-0">
              <div id="cadei2024smoke-nips-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  Machine Learning and AI have the potential to transform data-driven 
                  scientific discovery, enabling accurate predictions for several scientific 
                  phenomena. As many scientific questions are inherently causal, this paper 
                  looks at the causal inference task of treatment effect estimation, where 
                  we assume binary effects that are recorded as high-dimensional images in 
                  a Randomized Controlled Trial (RCT). Despite being the simplest possible 
                  setting and a perfect fit for deep learning, we theoretically find that many 
                  common choices in the literature may lead to biased estimates. To test the 
                  practical impact of these considerations, we recorded the first real-world 
                  benchmark for causal inference downstream tasks on high-dimensional observations 
                  as an RCT studying how garden ants (Lasius neglectus) respond to microparticles 
                  applied onto their colony members by hygienic grooming. Comparing 6 480 models 
                  fine-tuned from state-of-the-art visual backbones, we find that the sampling 
                  and modeling choices significantly affect the accuracy of the causal estimate, 
                  and that classification accuracy is not a proxy thereof. We further validated 
                  the analysis, repeating it on a synthetically generated visual data set 
                  controlling the causal model. Our results suggest that future benchmarks should 
                  carefully consider real downstream scientific questions, especially causal ones. 
                  Further, we highlight guidelines for representation learning methods to help 
                  answer causal questions in the sciences. All code and data will be released.</div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>

      <!-- Cadei 2024 ICML
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://icml.cc/" target="_blank">
          ICML
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="tortu2024nct" class="col p-0">
            <h5 class="title mb-0">Smoke and Mirrors in Causal Downstream Tasks (short)
            </h5>
            <div class="author">
              <em> 
                <b>Riccardo Cadei</b>;
                Lukas Lindorfer;
                Sylvia Cremer;
                Cordelia Schmid;
                Francesco Locatello;
              </em>  
            </div>

            <div><p class="periodical font-italic">
              Workshop in AI for Science: Scaling in AI for Scientific Discovery at ICML, 2024
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#cadei2024smoke-icml-abstract" role="button" aria-expanded="false" aria-controls="cadei2024smoke-icml-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://openreview.net/forum?id=gjd9E4IUur" target="_blank">Paper</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/CausalLearningAI/ISTAnt" target="_blank">Code</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://figshare.com/s/0970e149cfe72089c771?file=48137317" target="_blank">Data</a>
            </div>
    
            <div class="col mt-2 p-0">
              <div id="cadei2024smoke-icml-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  Machine Learning and AI have the potential to transform data-driven 
                  scientific discovery, enabling accurate predictions for several scientific 
                  phenomena. As many scientific questions are inherently causal, this paper 
                  looks at the causal inference task of treatment effect estimation, where 
                  we assume binary effects that are recorded as high-dimensional images in 
                  a Randomized Controlled Trial (RCT). Despite being the simplest possible 
                  setting and a perfect fit for deep learning, we theoretically find that many 
                  common choices in the literature may lead to biased estimates. To test the 
                  practical impact of these considerations, we recorded the first real-world 
                  benchmark for causal inference downstream tasks on high-dimensional observations 
                  as an RCT studying how garden ants (Lasius neglectus) respond to microparticles 
                  applied onto their colony members by hygienic grooming. Comparing 6 480 models 
                  fine-tuned from state-of-the-art visual backbones, we find that the sampling 
                  and modeling choices significantly affect the accuracy of the causal estimate, 
                  and that classification accuracy is not a proxy thereof. We further validated 
                  the analysis, repeating it on a synthetically generated visual data set 
                  controlling the causal model. Our results suggest that future benchmarks should 
                  carefully consider real downstream scientific questions, especially causal ones. 
                  Further, we highlight guidelines for representation learning methods to help 
                  answer causal questions in the sciences. All code and data will be released.</div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li> -->

      <!--Tortu 2024 JOSS-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://joss.theoj.org/" target="_blank">
          GitHub
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="tortu2024nct" class="col p-0">
            <h5 class="title mb-0">NetworkCausalTree: an R package for estimating heterogeneous effects under interference 
            </h5>
            <div class="author">
              <em> 
                Costanza Tortù;
                Falco J. Bargagli Stoffi;
                <b>Riccardo Cadei</b>;
                Laura Forastiere
              </em>  
            </div>

            <div><p class="periodical font-italic">
              GitHub (under review)
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#tortu2024cre-abstract" role="button" aria-expanded="false" aria-controls="tortu2024cre-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/fbargaglistoffi/NetworkCausalTree/blob/master/paper/paper.md" target="_blank">Paper</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/fbargaglistoffi/NetworkCausalTree" target="_blank">Code</a>
              <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://nsaph-software.github.io/CRE/" target="_blank">Website</a> -->
            </div>
    
            <div class="col mt-2 p-0">
              <div id="tortu2024cre-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  The NetworkCausalTree package introduces a machine 
                  learning method that uses tree-based algorithms and 
                  an Horvitz-Thompson estimator to assess the 
                  heterogeneity of treatment and spillover effects in 
                  clustered network interference. Causal inference 
                  studies typically assume no interference between 
                  individuals, but in real-world scenarios where 
                  individuals are interconnected through social, 
                  physical, or virtual ties, the effect of a treatment 
                  can spill over to other connected individuals in 
                  the network. To avoid biased estimates of treatment 
                  effects, interference should be considered. 
                  Understanding the heterogeneity of treatment and 
                  spillover effects can help policy-makers scale up 
                  interventions, target strategies more effectively, 
                  and generalize treatment spillover effects to 
                  other populations.</div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>
      
    </div>

    <div class="col-sm-1 align-self-end mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2024</h3>
    </div>
  </div>

  <!--2023-->
  <div class="row m-0 p-0" style="border-bottom: 1px solid #ddd;">
    <div class="col-sm-11 p-0">

      <!--Tec 2023 ICLR-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://iclr.cc/" target="_blank">
          ICLR
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="tec2023clim2pm" class="col p-0">
            <h5 class="title mb-0">Projecting the climate penalty on PM<sub>2.5</sub> pollution with spatial deep learning
            </h5>
            <div class="author">
              <em> 
                Mauricio Tec;
                <b>Riccardo Cadei</b>;
                <a href="https://scholar.google.co.uk/citations?user=RSwElNMAAAAJ&hl=en" target="_blank">Francesca Dominici</a>;
                Corwin Zigler
              </em>  
            </div>

            <div>
              <p class="periodical font-italic">
              Workshop in Tackling Climate Change with Machine Learning at ICLR, 2023          
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#tec2023clim2pm-abstract" role="button" aria-expanded="false" aria-controls="tec2023clim2pm-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.climatechange.ai/papers/iclr2023/63" target="_blank">Paper</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/NSAPH-Projects/clip2pm" target="_blank">Code</a>
            </div>
    
            <div class="col mt-2 p-0">
              <div id="tec2023clim2pm-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  The climate penalty measures the effects of a 
                  changing climate on air quality due to the interaction 
                  of pollution with climate factors, independently of 
                  future changes in emissions. This work introduces a 
                  statistical framework for estimating the climate 
                  penalty on soot pollution (PM 2.5), which has been 
                  linked to respiratory and cardiovascular diseases 
                  and premature mortality.
                  The framework is used to evaluate the disparities in 
                  future PM 2.5 exposure across racial/ethnic and income groups. 
                  The findings of this study have the potential to 
                  inform mitigation policy aiming to protect public 
                  health and promote environmental equity in addressing 
                  the effects of climate change.
                  The proposed methodology significantly improves upon 
                  existing statistical-based methods for estimating 
                  the climate penalty. It will use higher-resolution 
                  climate inputs---which current statistical approaches 
                  cannot accommodate---using an expressive and scalable 
                  predictive model based on spatial deep learning with 
                  spatiotemporal trend estimation. It will also integrate 
                  additional predictive data sources such as demographics 
                  and geology. This approach allows us to consider 
                  regional dependencies and synoptic weather patterns 
                  that influence PM 2.5, and deconvolve them from the 
                  effects of exogenous factors, such as the trends in 
                  increasing air quality regulations and other sources 
                  of unmeasured spatial heterogeneity. 
                </div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>

      <!--Cadei 2023 JOSS-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://joss.theoj.org/" target="_blank">
          JOSS
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="cadei2023cre" class="col p-0">
            <h5 class="title mb-0">CRE: An R package for interpretable discovery and inference of heterogeneous treatment effects
            </h5>
            <div class="author">
              <em> 
                <b>Riccardo Cadei</b><sup>*</sup>;
                Naeem Khoshnevis<sup>*</sup>; 
                Kwonsang Lee;
                Daniela Maria Garcia; 
                Falco J. Bargagli Stoffi
              </em>  
            </div>

            <div><p class="periodical font-italic">
              Journal of Open Source Software
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#cadei2023cre-abstract" role="button" aria-expanded="false" aria-controls="cadei2023cre-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://joss.theoj.org/papers/10.21105/joss.05587" target="_blank">Paper</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/NSAPH-Software/CRE" target="_blank">Code</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://nsaph-software.github.io/CRE/" target="_blank">Website</a>
            </div>
    
            <div class="col mt-2 p-0">
              <div id="cadei2023cre-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  In health and social sciences, it is critically 
                  important to identify interpretable subgroups of the 
                  study population where a treatment has notable 
                  heterogeneity in the causal effects with respect to 
                  the average treatment effect (ATE). Several 
                  approaches have already been proposed for heterogenous 
                  treatment effect (HTE) discovery, either estimating 
                  first the conditional average treatment effect (CATE) 
                  and identifying heterogeneous subgroups in a second 
                  stage, either in a direct data-driven procedure. 
                  Many of these methodologies are decision 
                  tree-based methodologies. Tree-based approaches are 
                  based on efficient and easily implementable recursive 
                  mathematical programming (e.g., HTE maximization), 
                  they can be easily tweaked and adapted to different 
                  scenarios depending on the research question of 
                  interest, and they guarantee a high degree of 
                  interpretability---i.e., the degree to which a human 
                  can understand the cause of a decision. Despite these 
                  appealing features, single-tree heterogeneity 
                  discovery is characterized by two main limitations: 
                  instability in the identification of the subgroups and 
                  reduced exploration of the potential heterogeneity. 
                  To accommodate these shortcomings, Bargagli et al. 
                  (2023) proposed Causal Rule Ensemble, a new method 
                  for interpretable HTE characterization in terms of 
                  decision rules, via an extensive exploration of 
                  heterogeneity patterns by an ensemble-of-trees 
                  approach, enforcing high stability in the discovery. 
                  CRE is an R package providing a flexible 
                  implementation of Causal Rule Ensemble algorithm.</div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>

      <!--Falco 2023 ArXiv-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://arxiv.org/abs/2009.09036" target="_blank">
          arXiv
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="bargagli2023cre" class="col p-0">
            <h5 class="title mb-0">Causal Rule Ensemble: Interpretable Discovery and Inference of Heterogeneous Treatment Effects
            </h5>
            <div class="author">
              <em> 
                Falco J. Bargagli-Stoffi<sup>*</sup>;
                <b>Riccardo Cadei</b><sup>*</sup>; 
                Kwonsang Lee; 
                <a href="https://scholar.google.co.uk/citations?user=RSwElNMAAAAJ&hl=en" target="_blank">Francesca Dominici</a>
              </em>  
            </div>

            <div><p class="periodical font-italic">
                arXiv (under review)
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bargagli2023cre-abstract" role="button" aria-expanded="false" aria-controls="bargagli2023cre-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2009.09036" target="_blank">arXiv</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/NSAPH-Software/CRE" target="_blank">Code</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://nsaph-software.github.io/CRE/" target="_blank">Website</a>
            </div>
    
            <div class="col mt-2 p-0">
              <div id="bargagli2023cre-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  In health and social sciences, it is critically important to identify subgroups of the study population where a treatment has notable heterogeneity in the causal effects with respect to the average treatment effect. Data-driven discovery of heterogeneous treatment effects (HTE) via decision tree methods has been proposed for this task. Despite its high interpretability, the single-tree discovery of HTE tends to be highly unstable and to find an oversimplified representation of treatment heterogeneity. To accommodate these shortcomings, we propose Causal Rule Ensemble (CRE), a new method to discover heterogeneous subgroups through an ensemble-of-trees approach. CRE has the following features: 1) provides an interpretable representation of the HTE; 2) allows extensive exploration of complex heterogeneity patterns; and 3) guarantees high stability in the discovery. The discovered subgroups are defined in terms of interpretable decision rules, and we develop a general two-stage approach for subgroup-specific conditional causal effects estimation, providing theoretical guarantees. Via simulations, we show that the CRE method has a strong discovery ability and a competitive estimation performance when compared to state-of-the-art techniques. Finally, we apply CRE to discover subgroups most vulnerable to the effects of exposure to air pollution on mortality for 35.3 million Medicare beneficiaries across the contiguous U.S.
                </div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>
      
    </div>

    <div class="col-sm-1 align-self-end mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>

  <!--2022-->
  <div class="row m-0 p-0" style="border-bottom: 1px solid #ddd;">
    <div class="col-sm-11 p-0">

      <!--Yuehiang 2022 CVPR-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://cvpr2022.thecvf.com/" target="_blank">
          CVPR
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="yuehiang2021" class="col p-0">
            <h5 class="title mb-0">Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective</h5>
            <div class="author">
              <em> 
                Yuejiang Liu;
                <b>Riccardo Cadei</b>;
                Jonas Schweizer;
                Sherwin Bahmani;
                <a href="https://scholar.google.com/citations?user=UIhXQ64AAAAJ&hl=en" target="_blank">Alexandre Alahi</a>
              </em>  
            </div>

            <div><p class="periodical font-italic">
                IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022 <br>
                Workshop on Distribution Shifts at NeurIPS, 2021
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#yuejiang2022cvpr-abstract" role="button" aria-expanded="false" aria-controls="yuejiang2022cvpr-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2111.14820" target="_blank">arxiv</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://ieeexplore.ieee.org/document/9879717" target="_blank">IEEE</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/vita-epfl/causalmotion" target="_blank">Code</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://openreview.net/forum?id=MPqliTsloys" target="_blank">Short Version (NeuriPS'21)</a>
            </div>
    
            <div class="col mt-2 p-0">
              <div id="yuejiang2022cvpr-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  Learning behavioral patterns from observational data has been a de-facto approach to motion forecasting. Yet, the current paradigm suffers from two shortcomings: brittle under covariate shift and inefficient for knowledge transfer. In this work, we propose to address these challenges from a causal representation perspective. We first introduce a causal formalism of motion forecasting, which casts the problem as a dynamic process with three groups of latent variables, namely invariant mechanisms, style confounders, and spurious features. We then introduce a learning framework that treats each group separately: (i) unlike the common practice of merging datasets collected from different locations, we exploit their subtle distinctions by means of an invariance loss encouraging the model to suppress spurious correlations; (ii) we devise a modular architecture that factorizes the representations of invariant mechanisms and style confounders to approximate a causal graph; (iii) we introduce a style consistency loss that not only enforces the structure of style representations but also serves as a self-supervisory signal for test-time refinement on the fly. Experiment results on synthetic and real datasets show that our three proposed components significantly improve the robustness and reusability of the learned motion representations, outperforming prior state-of-the-art motion forecasting models for out-of-distribution generalization and low-shot transfer.                </div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>
      
    </div>

    <div class="col-sm-1 align-self-end mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

  <!--2021-->
  <div class="row m-0 p-0" style="border-bottom: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      
     
      <!--Yuehiang 2021 NeurIPS-->
      <!-- <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://nips.cc/" target="_blank">
          NeurIPS
          </a>
        </div>
        
        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="yuehiang2021" class="col p-0">
            <h5 class="title mb-0">Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective (short) </h5>
            <div class="author">
              <em> 
                Yuejiang Liu;
                <b>Riccardo Cadei</b>;
                <a href="https://scholar.google.com/citations?user=UIhXQ64AAAAJ&hl=en" target="_blank">Alexandre Alahi</a>
              </em>  
            </div>

            <div><p class="periodical font-italic">
                Workshop in Distribution Shifts at NeurIPS, 2021
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#yuejiang2021neurips-abstract" role="button" aria-expanded="false" aria-controls="yuejiang2021neurips-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://openreview.net/pdf?id=MPqliTsloys" target="_blank">OpenReview</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/img/poster-nips2021.png" target="_blank">Poster</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/vita-epfl/causalmotion" target="_blank">Code</a>
            </div>
    
            <div class="col mt-2 p-0">
              <div id="yuejiang2021neurips-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  Learning behavioral patterns from observational data has been a de-facto approach to motion forecasting. Yet, the current paradigm suffers from two fundamental shortcomings: brittle under covariate shift and inefficient for knowledge transfer. In this work, we propose to address these challenges from a causal representation perspective. We first introduce a causal formalism of motion forecasting, which casts the problem as a dynamic process with physical mechanisms, style confounders, and spurious correlations. We then propose two components that explicitly promote the robustness and reusability of the learned motion representations: (i) unlike the common practice of merging datasets collected from different locations, we exploit their subtle distinctions by means of an invariance loss function, which encourages the model to suppress spurious correlations and capture physical mechanisms; (ii) we devise a modular architecture that factorizes the representations of physical laws and motion styles in a structured way, and progressively prune their dense connections during training to approximate a sparse causal graph. We empirically validate the strength of the proposed method for robust generalization in controlled real-world experiments. We finally discuss the challenges and opportunities in the presence of style shifts through synthetic simulations.
                </div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li> -->


      <!--Castello 2021 JoP-->
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
        <div class="col-sm-1 p-0 abbr">
          <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://cisbat.epfl.ch/" target="_blank">
          JoP
          </a>
        </div>

        <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
          <div id="castello2021" class="col p-0">
            <h5 class="title mb-0">Quantification of the available area for rooftop photovoltaic installation from overhead imagery using convolutional neural networks</h5>
            <div class="author">
              <em><a href="https://scholar.google.com/citations?user=JFdVZCcAAAAJ&hl=en" target="_blank">Roberto Castello</a>; 
                Alina Walch; 
                Raphael Attias; 
                <b>Riccardo Cadei</b>; 
                Shasha Jiang; 
                Jean-Louis Scartezzini</em>  
            </div>

            <div><p class="periodical font-italic">
                Journal of Physics: Conference Series, 2021
              </p>
            </div>
    
            <div class="col p-0">
              <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#castello2021-abstract" role="button" aria-expanded="false" aria-controls="castello2021-abstract">Abstract</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://iopscience.iop.org/article/10.1088/1742-6596/2042/1/012002" target="_blank">IOPscience</a>
              <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/riccardocadei/Rooftop-CNN-detection" target="_blank">Code</a>
            </div>
    
            <div class="col mt-2 p-0">
              <div id="castello2021-abstract" class="collapse">
                <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                  The integration of solar technology in the built environment is realized mainly through rooftop-installed panels. In this paper, we combine state-of-the-art Machine Learning and computer vision techniques together with high-resolution overhead images to provide a geo-localization of the available rooftop surfaces for solar panel installation. We further associate them to the corresponding buildings by means of a geospatial post-processing approach. The stand-alone Convolutional Neural Network used to segment suitable rooftop areas reaches an intersection over union of 64% and an accuracy of 93%, while a post-processing step using building database improves the rejection of false positives. The model is applied to a case study area in the canton of Geneva and the results are compared with another recent method used in the literature to derive the available area.</em>
                </div>
              </div>
            </div>
            
          </div>
        </div>
      </div></li>
    </div>

    
    <div class="col-sm-1 align-self-end mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2021</h3>
    </div>
  </div>

  </div>

  <!-- Footer -->
  <footer> 
    &copy; Copyright 2025 Riccardo Cadei.
  </footer>

  <!-- Core JavaScript Files -->
  <script src="/assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="/assets/js/popper.min.js" type="text/javascript"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="/assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="/assets/js/common.js"></script>



  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="/assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-54519238-1', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
